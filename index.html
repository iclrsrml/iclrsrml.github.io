<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="ICLR Workshop on Security in Machine Learning">

  <title>ICLR 2022 Workshop on Socially Responsible Machine Learning</title>

  <!-- Bootstrap core CSS -->
  <link href="bootstrap.min.css" rel="stylesheet">
</head>

<body>

<!-- Begin page content -->
<main role="main" class="container">
  <h1 class="mt-5 cneter">ICLR 2022 Workshop on Socially Responsible Machine Learning (SRML)
</h1>
  <p class="mb-0"><b>Date:</b> April 29, 2022 (Friday)</p>
  <p class="mb-0"><b>Location:</b> Virtual Only (co-located with <a href="https://iclr.cc/Conferences/2022/">ICLR 2022</a>)</p>
  <!-- <p> 
    <ul>
      <li>
        We've sent out the results for the papers. Check all the <a href="paper.html">accepted paper</a>.
      </li>
    </ul>
  </p> -->
  <!-- <p class="mb-0"><b>Contact:</b> xxx (this will email all organizers)</p> -->
  <p class="mb-0"><b>Abstract:</b></p>
  Machine learning (ML) systems have been increasingly used in many applications, ranging from decision-making systems (e.g., automated resume screening and pretrial release tool) to safety-critical tasks (e.g., face recognition, financial analytics and autonomous driving). Recently, the concept of foundation models has received significant attention in the ML community, which refers to the rise of models (e.g., BERT, GPT-3) that are trained on large-scale data and work surprisingly well in a wide range of downstream tasks. While there are many opportunities regarding foundation models, ranging from capabilities (e.g., language, vision, robotics, reasoning, human interaction), applications (e.g., law, healthcare, education, transportation), and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations), concerns and risks have been incurred that the models can inflict harm if they are not developed or used with care. It has been well-documented that ML models can:

    <p>
    <ul>
      <li>Inherit pre-existing social biases and exhibit discrimination against already-disadvantaged or marginalized social groups, such as BIPOC and LGBTQ+.</li>
      <li>Be vulnerable to security and/or privacy attacks that deceive the models and leak the sensitive information in training data, such as medical records and personal identifiable information (PII).</li>
      <li>Make hard-to-justify predictions with a lack of transparency and explanation.</li>
      <li>Be unreliable and unpredictable under domain shift or other input variations in real-life scenarios.</li>
    </ul>
    </p>
  <p>
      This workshop aims to build connections by bringing together both theoretical and applied researchers from various communities (e.g., machine learning, fairness &amp; ethics, security, privacy, etc.), with a focus on recent research and future directions for socially responsible machine learning problems in real-world systems.
    
  </p>
  <p>
  </p>
  <!-- <h2>Sponsor</h2> -->
  <!-- <p></p> -->

<h2>Important Dates</h2>
<ul>
  <li><b>Workshop paper submission deadline:</b> 02/25/2022 (<a href="https://www.timeanddate.com/time/zones/aoe">AoE</a>)</li>
  <li><b>Notification to authors:</b> 03/25/2022</li>
  <li><b>Camera ready deadline:</b> 04/10/2022</li>
  <li><b>Workshop day:</b> 04/29/2022</li>
</ul>
  <p></p>
	
<h2 id="accepted">Accepted Papers</h2>

Our workshop accepted <b>28 high quality papers</b>: <a href="paper.html">List of accepted papers</a>

<p></p>

<h2>Call For Papers</h2>

Although extensive studies have been conducted to increase trust in ML, many of them either focus on well-defined problems that enable nice tractability from a mathematical perspective but are hard to be adapted to real-world systems, or they mainly focus on mitigating risks in real-world applications without providing theoretical justifications. Moreover, most work studies fairness, privacy, transparency, and interpretability separately, while the connections among them are less explored. This workshop aims to bring together both theoretical and applied researchers from various communities (e.g., machine learning, fairness &amp; ethics, security, privacy, etc.). <b>We invite submissions on any aspect of the social responsibility and trustworthiness of machine learning, which includes but not limited to</b>:

<p>
<ul>
    <li>The intersection of various aspects of socially responsible and trustworthy ML: fairness, transparency, interpretability, privacy, robustness.</li>
    <li>The state-of-the-art research of socially responsible and trustworthy ML and their usage in applications.</li>
    <li>The possibility of using the most recent theoretical advancements to inform practice guidelines for deploying socially responsible and trustworthy ML systems.</li>
    <li>Providing insights about how we can automatically detect, verify, explain, and mitigate potential biases, privacy or other societal problems in existing models.</li>
    <li>Understanding the trade-offs or costs of achieving different goals in reality.</li>
    <li>Studying the social impacts of machine learning models that may inherently have bias, exhibit discrimination, or cause other undesired harms.</li>
</ul>
</p>
<p>
Reviewing will be performed in double-blind, with criteria include (a) relevance, (b) quality of the methodology and experiments, (c) novelty, (d) societal impacts.
<p>
<p>
  <p class="mb-0"><b>Poster deadline:</b> April 17, 2022 Anywhere on Earth (AoE)</p>
  <p class="mb-0"><b>Camera-ready deadline:</b> April 10, 2022 Anywhere on Earth (AoE)</p>
  <p class="mb-0"><b>Submission deadline:</b> Feb 25, 2022 Anywhere on Earth (AoE)</p>
  <p class="mb-0"><b>Notification sent to authors:</b> Mar 25, 2022 Anywhere on Earth (AoE)</p>
  <p class="mb-0"><b>Submission server:</b> <a href="https://cmt3.research.microsoft.com/ICLRSRML2022/" target="_blank">https://cmt3.research.microsoft.com/ICLRSRML2022/</a></p>
	
  <p class="mb-0"><b>Submission Format: </b> We welcome submissions up to 4 pages in ICLR Proceedings format (double-blind), excluding references and appendix. <a href="https://github.com/ICLR/Master-Template/raw/master/archive/iclr2022.zip">Style files</a>  are available.   We allow an unlimited number of pages for references and supplementary material, but reviewers are not required to review the supplementary material.  Unless indicated by the authors, we will provide PDFs of all accepted papers on <a href="https://iclrsrml.github.io/">https://iclrsrml.github.io/</a>.  There will be no archival proceedings.
  
    We are using CMT3 to manage submissions.
    </p>
    <p class="mb-0"><b>Contact: </b> Please email <a href="https://xiaocw11.github.io/">Chaowei Xiao</a> (xiaocw [at] umich [dot] edu) and <a href="https://huan-zhang.com/">Huan Zhang</a> (huan [at] huan-zhang [dot] com) for submission issues.
    </p>
    <!-- <p class="mb-0"><b>Ethics: </b> We ask that authors think about the broader impact and ethical considerations of their work. For example, authors may consider whether there is potential use for the data or methods to create or exacerbate unfair bias. Authors are not required to have a broader impact statement in their paper, but will be asked to submit one paragraph (3-4 sentences) as a separate field in OpenReview at the time of submission. See this guide for help with the statement. Reviewers will be asked to consult the ICLR 2021 code of ethics when reviewing submissions. Reviewers cannot reject papers based on ethical considerations, but in very rare cases, the workshop organizers may reject papers that blatantly violate the code of ethics (e.g., if the primary application directly causes harm or injury). 
    </p> -->
    
    
    
   </p>
  <p></p>


  <h2>Schedule</h2>
  <p><b>Workshop day:</b> 04/29/2022</p>
  <p><b>Time Zone:</b> US Eastern Time Zone (UTC-05:00)  </p>
  <p>Detailed schedule will be released once we confirm the availability of all speakers.</p>
  <!-- <p>The tentative schedule is subject to change prior to the workshop.</p> -->
  <!-- <p>Accepted paper can be found <a href="paper.html">here</a>.</p> -->
  <p></p>
  <h2>Organizing Committee</h2>
  <div class="row justify-content-around">
    <!-- <div class="col-lg-1"></div> -->
    <!-- </div> -->
      <div class="col-md-1">
      <img class="rounded-circle" src="imgs/chaowei.jpeg" width="150px" height="150px">
      <p style="width:150px;text-align:center;" ><a href="https://xiaocw11.github.io/"><b>Chaowei Xiao</b></a><br>
      (NVIDIA)</p>
    </div>

    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/huanzhang.jpeg" width="150px" height="150px">
      <p style="width:150px;text-align:center;" ><a href="https://huan-zhang.com"><b>Huan Zhang</b></a><br>
      (CMU)</p>
    </div>
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/xueru.png" width="150px" height="150px">
      <p style="width:150px;text-align:center;" ><a href="https://xueruzhang.github.io/"><b>Xueru Zhang</b></a><br>
      (Ohio State University)</p>
    </div>  
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/hongyang.png" width="150px" height="150px">
      <p style="width:150px;text-align:center;" ><a href="https://hongyanz.github.io/"><b>Hongyang Zhang</b></a><br>
      (Waterloo)</p>
    </div>
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/cihang.jpeg" width="150px" height="150px">
      <p style="width:150px;text-align:center;" ><a href="https://cihangxie.github.io/"><b>Cihang Xie</b></a><br>
      (UCSC)</p>
    </div>
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/beidi.png" width="150px" height="150px">
      <p style="width:150px;text-align:center;" ><a href="https://cs.stanford.edu/people/beidic/"><b>Beidi Chen</b></a><br>
      (Stanford)</p>
    </div>
  </div> 
  <div class="row justify-content-around">
  <div class="col-md-1">
    <img class="rounded-circle" src="imgs/xinchen.png" width="150px" height="150px">
      <p style="width:150px;text-align:center;" ><a href="https://sites.google.com/site/skywalkeryxc/"><b>Xinchen Yan</b></a><br>
    </p>
  </div>
<!-- </div> -->
  <div class="col-md-1">
    <img class="rounded-circle" src="imgs/yuke.png" width="150px" height="150px">
    <p style="width:150px;text-align:center;" ><a href="https://rpl.cs.utexas.edu/"><b>Yuke Zhu</b></a><br>
    (UT Austin/NVIDIA)</p>
  </div>
  <!-- <h2>Senior Organizing Committee</h2> -->
    <!-- <div class="row justify-content-around"> -->
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/boli.png" width="150px" height="150px">
      <p style="width:150px;text-align:center;" ><a href="https://aisecure.github.io/"><b>Bo Li</b></a><br>
      (UIUC)</p>
    </div>
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/zico.jpeg" width="150px" height="150px">
      <p style="width:150px;text-align:center;" ><a href="https://zicokolter.com/"><b>Zico Kolter</b></a><br>
      (CMU)</p>
    </div>

    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/dawn.png" width="150px" height="150px">
      <p style="width:150px;text-align:center;" ><a href="https://people.eecs.berkeley.edu/~dawnsong/"><b>Dawn Song</b></a><br>
      (UC Berkeley)</p>
    </div>
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/anima.png" width="150px" height="150px">
      <p style="width:150px;text-align:center;" ><a href="http://tensorlab.cms.caltech.edu/users/anima/"><b>Anima Anandkumar</b></a><br>
      (Caltech/NVIDIA)</p>
    </div>
    <!-- <div class="col-lg-1"></div> -->
  </div>
  <p></p>

<h2>Program Committee</h2>
<li>Chang Xiao (Columbia University)</li>
<li>Lifeng Huang (SunYat-sen university)</li>
<li>Kun Jin (University of Michigan, Ann Arbor)</li>
<li>Parinaz Naghizadeh (Ohio State University)</li>
<li>Rajkumar Theagarajan (University of California, Riverside)</li>
<li>Swetasudha Panda (Oracle Labs)</li>
<li>Xinlei Pan (UC Berkeley)</li>
<li>Aniruddha Saha (University of Maryland Baltimore County)</li>
<li>Xueru Zhang (University of Michigan)</li>
<li>Xingjun Ma (Deakin University)</li>
<li>Maura Pintor (University of Cagliari)</li>
<li>Hongyang Zhang (University of Waterloo)</li>
<li>Xinchen Yan (Waymo)</li>
<li>Jia Liu (The Ohio State University)</li>
<li>Junheng Hao (UCLA)</li>
<li>Gaurang Sriramanan (University of Maryland, College Park)</li>
<li>Xinwei Zhao (Drexel University)</li>
<li>Boxin Wang (University of Illinois at Urbana-Champaign)</li>
<li>Mingjie Sun (Carnegie Mellon University)</li>
<li>Adam Kortylewski (Max Planck Institute for Informatics)</li>
<li>Nataniel Ruiz (Boston University)</li>
<li>Yulong Cao (University of Michigan, Ann Arbor</li>
<li>Anshuman Suri (University of Virginia)</li>
<li>Muhammad Awais (Kyung-Hee University)</li>
<li>Akshayvarun Subramanya (UMBC)</li>
<li>Mohammad Mahdi Khalili (University of Delaware)</li>
<li>Jiachen Sun (University of Michigan)</li>
<li>Chulin Xie (University of Illinois at Urbana-Champaign)</li>
<li>Won Park (University of Michigan)</li>
<li>Chirag Agarwal (Adobe)</li>



 
</body></html>
